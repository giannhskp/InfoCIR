import os
import subprocess
import torch
import pickle
import open_clip
import numpy as np
from PIL import Image
from collections import Counter

class FreedomRetrievalSystem:
    def __init__(self, load_features=False, features_path=None, gpu=0):
        """
        Initialize settings for the 'create_features' part (dataset, backbone, GPU, etc.).
        """
        self.backbone = "clip"
        self.gpu_id = gpu
        self.device = torch.device(f"cuda:{gpu}" if torch.cuda.is_available() else "cpu")

        self.corpus_file = None
        self.imagenet_r_file = None
        
        # Model placeholders
        self.model = None
        self.preprocess = None
        self.tokenizer = None
        self.load_features = load_features
        self.features_path = features_path
        
    def create_database(self, work_dir):
        """
        Call create_features.py with the appropriate arguments
        """
        if self.load_features and self.features_path:
            if (os.path.exists(os.path.join(self.features_path, "imagenet_r", "full_imagenet_r_features.pkl"))
                and os.path.exists(os.path.join(self.features_path, "imagenet_r", "full_imagenet_r_names.pkl"))
                and os.path.exists(os.path.join(self.features_path, "corpus", "open_image_v7_class_names.pkl"))):
                
                self.corpus_file = os.path.join(self.features_path, "corpus", "open_image_v7_class_names.pkl")
                self.imagenet_r_file = os.path.join(self.features_path, "imagenet_r", "full_imagenet_r_features.pkl")

                return

        script_path = os.path.join(os.path.dirname(__file__), "src/create_features.py")
        command = [
            "python",
            script_path,
            "--dataset",
            "corpus",
            "--backbone",
            self.backbone,
            "--gpu",
            str(self.gpu_id)
        ]
        print(f"Running: {' '.join(command)}")
        subprocess.run(command, check=True)
        
        print("create_database() done. Features have been generated by create_features.py")

        save_dir = os.path.join(work_dir, f"{self.backbone}_features", "corpus")

        save_file = os.path.join(save_dir, "open_image_v7_class_names.pkl")
        self.corpus_file = save_file

        command = [
            "python",
            script_path,
            "--dataset",
            "imagenet_r",
            "--backbone",
            self.backbone,
            "--gpu",
            str(self.gpu_id)
        ]
        print(f"Running: {' '.join(command)}")
        subprocess.run(command, check=True)
        
        print("create_database() done. Features have been generated by create_features.py")

        save_dir = os.path.join(work_dir, f"{self.backbone}_features", "imagenet_r")

        dataset_type = "full"
        save_file = os.path.join(
                save_dir, f"{dataset_type}_imagenet_r_features.pkl"
            )
        self.imagenet_r_file = save_file
            
        
    def query(self, image_path, text_mod, topk=5):
        """
        Mimic the entire logic from retrieval_example.py, 
        given a query image path, a text modifier, and the number of top images to retrieve.
        """
        # --- Config ---
        model_name = "ViT-L-14"
        pretrained = "openai"
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        kappa = 20    # Number of proxy images
        miu = 7       # Number of most frequent labels to keep
        ni = 7        # Nearest labels per proxy image

        # --- Load model ---
        model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained)
        tokenizer = open_clip.get_tokenizer(model_name)
        model.to(device).eval()

        print("Model loaded successfully.")

        # --- Load database features ---
        with open(self.imagenet_r_file, "rb") as f:
            data = pickle.load(f)
        image_paths = data["path"]
        image_feats_np = data["feats"]
        image_features = torch.from_numpy(image_feats_np).float().to(device)
        image_features = image_features / image_features.norm(dim=1, keepdim=True)        
        print("Image features loaded successfully.")

        print(f"Loading corpus features from: {self.corpus_file}")

        # --- Load text corpus features ---
        with open(self.corpus_file, "rb") as f:
            corpus_data = pickle.load(f)
        text_corpus_labels = corpus_data["prompts"]
        corpus_feats_np = corpus_data["feats"]
        text_corpus_feats = torch.from_numpy(corpus_feats_np).float().to(device)
        text_corpus_feats = text_corpus_feats / text_corpus_feats.norm(dim=1, keepdim=True)

        print("Text corpus features loaded successfully.")

        # --- Encode query image ---
        query_image = preprocess(Image.open(image_path).convert("RGB")).unsqueeze(0).to(device)
        with torch.no_grad():
            image_feat = model.encode_image(query_image)
            image_feat = image_feat / image_feat.norm(dim=-1, keepdim=True)

        print("Query image encoded successfully.")

        # --- Step 1: Retrieve proxy images ---
        sim_img = torch.matmul(image_feat, image_features.T)  # shape: (1, N)
        topk_values, topk_indices = torch.topk(sim_img, kappa, dim=1)
        proxy_feats = image_features[topk_indices.squeeze(0)]
        
        print("Top-k proxy images retrieved successfully.")

        # --- Step 2: Add self-feature if max similarity is low ---
        if sim_img.max().item() < 0.98:
            print("Adding self feature to proxies.")
            proxy_feats = torch.cat([image_feat, proxy_feats[:-1]], dim=0)
            
        print("Proxy features prepared successfully.")

        # --- Step 3: Find top-Ni labels per proxy image ---
        with torch.no_grad():
            sim_labels = torch.matmul(proxy_feats, text_corpus_feats.T)  # shape: (kappa, T)
            _, top_label_indices = torch.topk(sim_labels, ni, dim=1)
            top_label_indices = top_label_indices.cpu().numpy()

        print("Top-Ni labels per proxy image retrieved successfully.")

        # --- Step 4: Collect candidate labels ---
        candidate_labels = [text_corpus_labels[i] for row in top_label_indices for i in row]

        # --- Step 5: Frequency count and select top-MIU labels ---
        label_counts = Counter(candidate_labels)
        most_common = label_counts.most_common(miu)
        selected_labels = [label for label, _ in most_common]
        counts = [count for _, count in most_common]
        max_count = max(counts) if counts else 1  # Avoid division by zero
        weights = [count / max_count for count in counts]  # MAX-NORMALIZATION (FIXED)

        print("Selected labels and their counts:")

        # --- Step 6: Compose text prompts (label + domain) ---
        composed_prompts = [f"{label} {text_mod}" for label in selected_labels]  # âœ“ Correct order
        print("Composed prompts:")
        for p in composed_prompts:
            print("  -", p)

        print("Composed prompts prepared successfully.")

        # --- Step 7: Encode composed text prompts ---
        with torch.no_grad():
            tokens = tokenizer(composed_prompts, context_length=model.context_length).to(device)
            text_feats = model.encode_text(tokens)
            text_feats = text_feats / text_feats.norm(dim=-1, keepdim=True)  # Individual normalization

        print("Text features encoded successfully.")

        # --- Step 8: Weighted fusion of text features ---
        weights_tensor = torch.tensor(weights, dtype=torch.float32, device=device).view(1, -1, 1)
        text_feats = text_feats.view(1, miu, -1)
        fused_query = (text_feats * weights_tensor).sum(dim=1)  # NO RE-NORMALIZATION (FIXED)

        print("Text features fused successfully.")

        # --- Step 9: Retrieve most similar images ---
        with torch.no_grad():
            sim_scores = torch.matmul(fused_query, image_features.T)  # (1, N)
            top_indices = torch.topk(sim_scores, topk, dim=1).indices.squeeze(0).cpu().numpy()

        print("Most similar images retrieved successfully.")

        names_file = self.imagenet_r_file.replace("_features.pkl", "_names.pkl")
        with open(names_file, "rb") as f:
            image_names = pickle.load(f)
            
        print("Image names loaded successfully.")

        # 10) Return results
        results = []
        for i, idx in enumerate(top_indices, 1):
            score = sim_scores[0][idx].item()
            results.append((image_names[idx], score))

        return results